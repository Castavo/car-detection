{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIC: Introduction to Visual Computing - 2021/22\n",
    "## Assignment 2\n",
    "\n",
    "**Instructor:** Maria Vakalopoulou\n",
    "**T.A.:** Joseph Boyd\n",
    "**Due Date:** March 1, 2022\n",
    "\n",
    "This is VIC Assignment 2. This time you are to implement a system that outputs object detection bounding boxes of cars in a dashcam videos. You are expected to submit your prediction to a Kaggle challenge at the following link, where you will also find the dataset and further instructions:\n",
    "\n",
    "https://www.kaggle.com/t/1df65691991d413ab190f6cc4d31b968\n",
    "\n",
    "You have a set of frames available for training in the `train/` directory, and their bounding boxes in `train.csv`, having format:\n",
    "\n",
    "```x, y, width, height```\n",
    "\n",
    "Your task is to produce bounding boxes for each frame in the `test/` directory.  **N.B.** Because of limitations of in-class Kaggle, your final submission file will be of a slightly different format to `train.csv`.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Submissions are evaluated with respect to the Sørensen–Dice coefficient,\n",
    "\n",
    "$$DSC = \\frac{2|X \\cap Y|}{|X| + |Y|},$$\n",
    "\n",
    "the intersection of the prediction X and the ground truth solution Y over the sum of their parts. The minimum is 0 (no intersection), and the maximum is 1 (perfect overlap). The mean DSC over all test images is your final score. **N.B.** that although the challenge is posed as an object detection problem, it is evaluated as a segmentation problem i.e. X and Y will be binary masks (see below). This is due to some limitations of Kaggle as used in-class mode.\n",
    "\n",
    "An unspecified 50% split of the test data contributes to a \"public leaderboard\", with the remaining data contributing to a \"private leaderboard\", which is not visible until the end of the competition. This is to prevent overfitting to the test data.\n",
    "\n",
    "## Submitting to Kaggle\n",
    "\n",
    "Submissions to the Kaggle challenge can be made in the form of a .csv file (see `sample_submission.csv`), consisting of two columns with one row per image:\n",
    "```\n",
    "Id,Predicted\n",
    "test/001.jpg,192425 100 193705 100 ...\n",
    "test/002.jpg,192425 100 193705 100 ...\n",
    "test/003.jpg,192425 100 193705 100 ...\n",
    "...\n",
    "```\n",
    "`Id` - the image id, which is the path to the image from the project root--must be exact.\n",
    "\n",
    "`Predicted` - The [run length encoding](https://en.wikipedia.org/wiki/Run-length_encoding) of the binary mask resulting from your concatenated bounding boxes. It is recommended to use the supplied function `run_length_encoding` to automate this. An example is given in the `Assignment2.ipynb` notebook. **N.B.** If you change the size of the images during your pipeline, be sure to resize your final bounding boxes to  (1280x720).\n",
    "\n",
    "## Grading\n",
    "\n",
    "Your work will be evaluated according to the following:\n",
    "\n",
    "- Solution design (40%): algorithmic complexity, technical innovation, performance (as evaluated on Kaggle). Simple ideas can achieve full marks if they are well-argued and perform well.\n",
    "\n",
    "- Implementation (40%): code quality, efficiency, clarity of documentation (code should be well commented). You should submit all code required to train/test your pipeline in a `.ipynb` notebook or a set of `.py` file(s).\n",
    "\n",
    "- Report (~1 page) (20%): Description of pipeline and justification of design choices, results and failure cases. In general, we want to know why you did one thing and not another.\n",
    "\n",
    "**PLUS** the best 5 leaderboard submissions will receive +1 for the grade of the assignment.\n",
    "\n",
    "**N.B.** This is an individual assignment. All students are expected to make at least one Kaggle submission and submit their own project code and report.\n",
    "\n",
    "You should send your assignment by email to maria.vakalopoulou@centralesupelec.fr, the name of the subject of the email should be: VIC\\_Assignment2\\_name.\n",
    "\n",
    "## FAQ\n",
    "\n",
    "**Q:** Can I use external datasets?\n",
    "**A:** Although we have provided extra training data anyway, we are relaxing the constraint on external datasets. So, yes, you can.\n",
    "\n",
    "**Q:** Must I code algorithms from scratch?\n",
    "**A:** You will be graded on the design/implementation of your solution pipeline, which ordinarily will comprise multiple algorithms (e.g. filters, features, machine learning). Unlike the labs and previous assignment, you are not required to code these individual algorithms.\n",
    "\n",
    "**Q:** Can my pipeline take a long time to run?\n",
    "**A:** It is acceptable if your training and/or testing takes some hours to run. However, in this case it should be shown that this is fully warranted.\n",
    "\n",
    "**Q:** Can I use deep learning?\n",
    "**A:** You are quite free in the design of your solution pipeline. However, **NO DEEP LEARNING APPROACHES ARE ALLOWED**. You should use classic methods to complete this assignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ground_truth = pd.read_csv('./train.csv')\n",
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage.io import imread\n",
    "\n",
    "\n",
    "H, W = 720, 1280\n",
    "N = len(df_ground_truth)\n",
    "\n",
    "\n",
    "def read_frame(df_annotation, frame):\n",
    "    \"\"\"Read frames and create integer frame_id-s\"\"\"\n",
    "    file_path = df_annotation[df_annotation.index == frame]['frame_id'].values[0]\n",
    "    return imread(file_path)\n",
    "\n",
    "def annotations_for_frame(df_annotation, frame):\n",
    "    assert frame in df_annotation.index\n",
    "    bbs = df_annotation[df_annotation.index == frame].bounding_boxes.values[0]\n",
    "\n",
    "    if pd.isna(bbs): # some frames contain no vehicles\n",
    "        return []\n",
    "\n",
    "    bbs = list(map(lambda x : int(x), bbs.split(' ')))\n",
    "    return np.array_split(bbs, len(bbs) / 4)\n",
    "\n",
    "def show_annotation(df_annotation, frame):\n",
    "    img = read_frame(df_annotation, frame)\n",
    "    bbs = annotations_for_frame(df_annotation, frame)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 12))\n",
    "\n",
    "    for x, y, dx, dy in bbs:\n",
    "\n",
    "        rect = patches.Rectangle((x, y), dx, dy, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    ax.imshow(img)\n",
    "    ax.set_title('Annotations for frame {}.'.format(frame))\n",
    "\n",
    "def bounding_boxes_to_mask(bounding_boxes, H, W):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts set of bounding boxes to a binary mask\n",
    "    \"\"\"\n",
    "\n",
    "    mask = np.zeros((H, W))\n",
    "    for x, y, dx, dy in bounding_boxes:\n",
    "        mask[y:y+dy, x:x+dx] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "def run_length_encoding(mask):\n",
    "\n",
    "    \"\"\"\n",
    "    Produces run length encoding for a given binary mask\n",
    "    \"\"\"\n",
    "    \n",
    "    # find mask non-zeros in flattened representation\n",
    "    non_zeros = np.nonzero(mask.flatten())[0]\n",
    "    padded = np.pad(non_zeros, pad_width=1, mode='edge')\n",
    "    \n",
    "    # find start and end points of non-zeros runs\n",
    "    limits = (padded[1:] - padded[:-1]) != 1\n",
    "    starts = non_zeros[limits[:-1]]\n",
    "    ends = non_zeros[limits[1:]]\n",
    "    lengths = ends - starts + 1\n",
    "\n",
    "    return ' '.join(['%d %d' % (s, l) for s, l in zip(starts, lengths)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def f_display(frame_id):\n",
    "    show_annotation(df_ground_truth, frame_id)\n",
    "\n",
    "interact(f_display, frame_id=widgets.IntSlider(min=1, max=N, step=1, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Kaggle submission file\n",
    "\n",
    "Suppose we have a set of bounding boxes of format `x, y, width, height`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes = [[0, 0, 5, 5], [5, 5, 5, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let's say they are the same for all test images (yours won't be). Then, we can create a Kaggle submission file like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = sorted(os.listdir('./test/'))\n",
    "\n",
    "rows = []\n",
    "\n",
    "for file_name in test_files:\n",
    "\n",
    "    rle = run_length_encoding(bounding_boxes_to_mask(bounding_boxes, H, W))\n",
    "    rows.append(['test/' + file_name, rle])\n",
    "\n",
    "df_prediction = pd.DataFrame(columns=['Id', 'Predicted'], data=rows).set_index('Id')\n",
    "df_prediction.to_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying stuff out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juste SIFT et classer élément de voiture / pas élément de voiture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import SIFT_create, imread, drawKeypoints\n",
    "from tqdm.notebook import tqdm\n",
    "sift = SIFT_create()\n",
    "\n",
    "train_files = [os.path.join(\"train\", path) for path in os.listdir('./train/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_labeled_features(df_annotation):\n",
    "    \"\"\" \n",
    "    Returns SIFT features for all images labeled as \"part of a car\" or not\n",
    "    The labeling is done thanks to the keypoints and bounding boxes\n",
    "    \"\"\"\n",
    "    features, labels = [], []\n",
    "\n",
    "    for frame in tqdm(range(1, len(df_annotation)+1)):\n",
    "        image = read_frame(df_annotation, frame)\n",
    "        bbs = annotations_for_frame(df_annotation, frame)\n",
    "        kp, f = sift.detectAndCompute(image, None)\n",
    "\n",
    "        features += f.tolist()\n",
    "        labels += label_keypoints(kp, bbs).tolist()\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "def label_keypoints(keypoints, bounding_boxes):\n",
    "    coords = np.array([kp.pt for kp in keypoints])\n",
    "\n",
    "    low_bbs = np.array([bb[0:2] for bb in bounding_boxes]) # shape = (M, 2)\n",
    "    high_bbs = low_bbs + np.array([bb[2:] for bb in bounding_boxes])\n",
    "\n",
    "    is_coord_good = (low_bbs[np.newaxis, ...] <= coords[:, np.newaxis, :]) & (coords[:, np.newaxis, :] <= high_bbs[np.newaxis, ...]) # (N, M, 2)\n",
    "\n",
    "    is_kp_good = (is_coord_good[:, :, 0] & is_coord_good[:, :, 1]).any(1)\n",
    "\n",
    "    return is_kp_good.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = collect_labeled_features(df_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(train_files[0])\n",
    "\n",
    "keypoints, features  = sift.detectAndCompute(image, None)\n",
    "\n",
    "image_w_keypoints = drawKeypoints(image, keypoints, image)\n",
    "\n",
    "plt.imshow(image_w_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb1 = 100, 100, 50, 50\n",
    "bb2 = 300, 300, 50, 50\n",
    "bb3 = 900, 200, 100, 100\n",
    "M = 3\n",
    "\n",
    "low_bbs = np.array([bb1[0:2], [*bb2[0:2]], [*bb3[0:2]]]) # shape = (M, 2)\n",
    "high_bbs = low_bbs + np.array([[*bb1[2:]], [*bb2[2:]], [*bb3[2:]]])\n",
    "\n",
    "coords = np.array([kp.pt for kp in keypoints]) # shape = (N, 2)\n",
    "\n",
    "is_good = (low_bbs[np.newaxis, ...] <= coords[:, np.newaxis, :]) & (coords[:, np.newaxis, :] <= high_bbs[np.newaxis, ...]) # (N, M, 2)\n",
    "\n",
    "is_kp_good = (is_good[:, :, 0] & is_good[:, :, 1]).any(1)\n",
    "\n",
    "good_coords = coords[is_kp_good]\n",
    "\n",
    "good_coords.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.scatter(good_coords[:, 0], good_coords[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
